{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f100440e",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In this notebook, we will create and refine features to improve model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c14a2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b99cc",
   "metadata": {},
   "source": [
    "# I. Data daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d40aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "read_dir = '../data/processed/'\n",
    "train_data = pd.read_excel(read_dir + 'train_data.xlsx')\n",
    "test_data = pd.read_excel(read_dir + 'test_data.xlsx')\n",
    "X_train = pd.read_excel(read_dir + 'X_train.xlsx')\n",
    "y_train = pd.read_excel(read_dir + 'y_train.xlsx')\n",
    "X_test = pd.read_excel(read_dir + 'X_test.xlsx')\n",
    "y_test = pd.read_excel(read_dir + 'y_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab3e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['spread'] = train_data['tempmax'] - train_data['tempmin']\n",
    "train_data['temp_dew_diff'] = train_data['temp'] - train_data['dew']\n",
    "train_data['feelslike_diff'] = train_data['feelslike'] - train_data['temp']\n",
    "train_data['is_heatwave'] = (train_data['tempmax'].rolling(window=3, min_periods=1).min() >= 35).astype(int)\n",
    "train_data['PET'] = (0.0023 * train_data['solarenergy'] * 0.408 * np.sqrt(train_data['tempmax'] - train_data['tempmin']) * (train_data['temp'] + 17.8))\n",
    "train_data['daylight_duration_hours'] = (train_data['sunset'] - train_data['sunrise']).dt.total_seconds() / 3600\n",
    "train_data['wind_U'] = train_data['windspeed'] * np.sin(2 * np.pi * train_data['winddir'] / 360)\n",
    "train_data['wind_V'] = train_data['windspeed'] * np.cos(2 * np.pi * train_data['winddir'] / 360)\n",
    "train_data['pressure_daily_change'] = train_data['sealevelpressure'].diff(3)\n",
    "train_data['solar_cloud_interaction'] = train_data['solarradiation'] * (1 - (train_data['cloudcover'] / 100))\n",
    "train_data['wind_gust_ratio'] = train_data['windgust'] / (train_data['windspeed'] + 1e-6)\n",
    "train_data['month_sin'] = np.sin(2 * np.pi * train_data['datetime'].dt.month / 12)\n",
    "train_data['month_cos'] = np.cos(2 * np.pi * train_data['datetime'].dt.month / 12)\n",
    "train_data['day_sin'] = np.sin(2 * np.pi * train_data['datetime'].dt.day_of_year / 365.25)\n",
    "train_data['day_cos'] = np.cos(2 * np.pi * train_data['datetime'].dt.day_of_year / 365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f52bab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3134 entries, 0 to 3133\n",
      "Columns: 263 entries, 7D_AVG_DEW to pressure_daily_change\n",
      "dtypes: float64(263)\n",
      "memory usage: 6.3 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_30280\\2240397034.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df[col] = train_data[col]\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_30280\\2240397034.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df[col] = train_data[col]\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_30280\\2240397034.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df[col] = train_data[col]\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_30280\\2240397034.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df[col] = train_data[col]\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_30280\\2240397034.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df[col] = train_data[col]\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_30280\\2240397034.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df[col] = train_data[col]\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_30280\\2240397034.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df[col] = train_data[col]\n"
     ]
    }
   ],
   "source": [
    "roll_cols = ['dew', 'humidity', 'precip', 'precipcover', \n",
    "            'windgust', 'windspeed',  'sealevelpressure', \n",
    "            'cloudcover', 'visibility', 'solarradiation', \n",
    "            'solarenergy', 'uvindex', 'conditions_Clear', \n",
    "            'conditions_Overcast', 'conditions_Partially cloudy', \n",
    "            'conditions_Rain', 'conditions_Rain, Overcast', \n",
    "            'conditions_Rain, Partially cloudy','spread', \n",
    "            'temp_dew_diff', 'feelslike_diff', 'is_heatwave', \n",
    "            'PET', 'daylight_duration_hours', 'wind_U', 'wind_V']\n",
    "\n",
    "lag_cols = ['spread', 'humidity', 'dew', 'precip',\n",
    "            'precipcover', 'solarradiation',\n",
    "            'sealevelpressure', 'windspeed', 'winddir',\n",
    "            'windgust', 'cloudcover', 'visibility']\n",
    "\n",
    "cols = ['day_cos', 'day_sin', 'month_cos', 'month_sin', \n",
    "        'wind_gust_ratio', 'solar_cloud_interaction', \n",
    "        'pressure_daily_change']\n",
    "\n",
    "windows = [7, 28, 56, 91]\n",
    "lags = [1, 3, 5, 7]\n",
    "\n",
    "features_df = pd.DataFrame(index=train_data.index)\n",
    "\n",
    "all_new_columns = []\n",
    "\n",
    "for col in roll_cols:\n",
    "    col_name_upper = col.upper()\n",
    "    for w in windows:\n",
    "        mean_name = f\"{w}D_AVG_{col_name_upper}\"\n",
    "        var_name = f\"{w}D_VAR_{col_name_upper}\"\n",
    "        \n",
    "        mean_series = train_data[col].shift(1).rolling(window=w).mean()\n",
    "        mean_series.name = mean_name\n",
    "        \n",
    "        var_series = train_data[col].shift(1).rolling(window=w).var()\n",
    "        var_series.name = var_name\n",
    "        \n",
    "        all_new_columns.append(mean_series)\n",
    "        all_new_columns.append(var_series)\n",
    "\n",
    "for col in lag_cols:\n",
    "    col_name_upper = col.upper()\n",
    "    for l in lags:\n",
    "        lag_name = f\"{col_name_upper}_LAG_{l}\"\n",
    "        \n",
    "        lag_series = train_data[col].shift(l)\n",
    "        lag_series.name = lag_name\n",
    "        \n",
    "        all_new_columns.append(lag_series)\n",
    "\n",
    "features_df = pd.concat([features_df] + all_new_columns, axis=1)\n",
    "\n",
    "for col in cols:\n",
    "    features_df[col] = train_data[col] \n",
    "\n",
    "features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c89fdb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu dữ liệu tập train test để training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6e81e1",
   "metadata": {},
   "source": [
    "# II. Data hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adb8d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data_h = pd.read_excel(read_dir + 'train_data_h.xlsx')\n",
    "test_data_h = pd.read_excel(read_dir + 'test_data_h.xlsx')\n",
    "X_train_h = pd.read_excel(read_dir + 'X_train_h.xlsx')\n",
    "y_train_h = pd.read_excel(read_dir + 'y_train_h.xlsx')\n",
    "X_test_h = pd.read_excel(read_dir + 'X_test_h.xlsx')\n",
    "y_test_h = pd.read_excel(read_dir + 'y_test_h.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22f2790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính toán các feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc0e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu dữ liệu tập train test để training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
